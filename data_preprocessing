Steps for data preprocessing:


    Get Rid of Extra Spaces
    Select and Treat All Blank Cells
    Convert Numbers Stored as Text into Numbers
    Remove Duplicates
    Highlight Errors
    Change Text to Lower/Upper/Proper Case
    Spell Check
    Delete all Formatting

https://www.digitalvidya.com/blog/data-cleaning-techniques/


===================================================================

1. Remove Unwanted observations
The first step to data cleaning is removing unwanted observations from your dataset.
This includes duplicate or irrelevant observations.


Duplicate observations
Duplicate observations most frequently arise during data collection, such as when you:
    Combine datasets from multiple places
    Scrape data
    Receive data from clients/other departments


Irrelevant observations
Irrelevant observations are those that don’t actually fit the specific problem that you’re trying to solve.
    For example, if you were building a model for Single-Family homes only, you wouldn't want observations for Apartments in there.
    This is also a great time to review your charts from Exploratory Analysis. You can look at the distribution charts for categorical      features to see if there are any classes that shouldn’t be there.
    Checking for irrelevant observations before engineering features can save you many headaches down the road.


2. Fix Structural Errors
As you can see:

    'composition' is the same as 'Composition'
    'asphalt' should be 'Asphalt'
    'shake-shingle' should be 'Shake Shingle'

3. Filter Unwanted Outliers

4. Handle Missing Data

===========================================================================





Data scientists … spend from 50 per cent to 80 per cent of their time mired in this more mundane labour of collecting and preparing unruly digital data, before it can be explored for useful nuggets.




Machine learning Lifecycle:

    Gathering Data
    Data preparation:  In this, we find Correlations, general trends, and outliers.
    Data Wrangling:
	Data wrangling is the process of cleaning and converting raw data into a useable format. It is the process of cleaning the data, 	 selecting the variable to use, and transforming the data in a proper format to make it more suitable for analysis in the next step. It 		is one of the most important steps of the complete process. Cleaning of data is required to address the quality issues.
	It is not necessary that data we have collected is always of our use as some of the data may not be useful. In real-world 		applications, collected data may have various issues, including:

    Missing Values
    Duplicate data
    Invalid data
    Noise

    Analyse Data
    Train the model
    Test the model
    Deployment




Data preprocessing steps:

    Getting the dataset
    Importing libraries
    Importing datasets
    Finding Missing Data
    Encoding Categorical Data
    Splitting dataset into training and test set
    Feature scaling: Feature scaling is the final step of data preprocessing in machine learning. It is a technique to standardize the 	    independent variables of the dataset in a specific range. In feature scaling, we put our variables in the same range and in the same scale so that no any variable dominate the other variable. A machine learning model is based on Euclidean distance, and if we do not scale the variable, then it will cause some issue in our machine learning model.



Outliers: Outlier is an observation which contains either very low value or very high value in comparison to other observed values. An outlier may hamper the result, so it should be avoided.

Multicollinearity: If the independent variables are highly correlated with each other than other variables, then such condition is called Multicollinearity. It should not be present in the dataset, because it creates problem while ranking the most affecting variable.
Underfitting and Overfitting: If our algorithm works well with the training dataset but not well with test dataset, then such problem is called Overfitting. And if our algorithm does not perform well even with training dataset, then such problem is called underfitting.Outliers: Outlier is an observation which contains either very low value or very high value in comparison to other observed values. An outlier may hamper the result, so it should be avoided.

Multicollinearity: If the independent variables are highly correlated with each other than other variables, then such condition is called Multicollinearity. It should not be present in the dataset, because it creates problem while ranking the most affecting variable.
Underfitting and Overfitting: If our algorithm works well with the training dataset but not well with test dataset, then such problem is called Overfitting. And if our algorithm does not perform well even with training dataset, then such problem is called underfitting.



There are three types of logistic regression:

    Binary(0/1, pass/fail)
    Multi(cats, dogs, lions)
    Ordinal(low, medium, high)













Currently working on Building SDK libraries, developing Django,Flask framework, Fastapi,JWT,Jose etc. Also integrating client API to the AWS lambda writing own Lambda Authenticator script and connect via API gateway. 

* I have hands-on experience in the coding state of the art Machine Learning and Deep Learning models for Computer Vision and NLP tasks using TensorFlow, PyTorch, Keras and Scikit-learn. Also the ability to come up with novel models.
* Good knowledge of coding concepts, design patterns and advanced algorithms.
* Deep understanding of the theory behind machine learning algorithms from a mathematical, statistical and probabilistic point of view. Heavy course load to back it up.
* Currently undertaking projects in Deep Learning and Computer Vision to come up with novel architecture and framework to preserve privacy in vision-based emotion classification systems. 
* Experienced in developing intelligent multi-purpose systems using cross-domain concepts including Machine Learning, Deep Learning, Computer Vision, Robotics, Embedded Systems, sensors and IoT.
*I like to think creatively, apply knowledge from different domains and combine them together to develop an end to end project/system which is clearly depicted in my projects. I am a life long learner and am mostly flexible and open for new challenges and concepts to push my horizon further. 
