{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple linear regression\n",
    "y = m3D3 + m1x1 + m2x2 + c\n",
    "D3 is dummy variable\n",
    "Create dummy variable for States or string values\n",
    "Dummy variable trap: Never include both dummy variable at same time (0 and 1)\n",
    "By doing this it is duplicacy and called multi colinearity\n",
    "When ever building  a model always include only one dummy variable\n",
    "Always omit one dummy variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Linear regression\n",
    "1. we dont use every independent values or every column\n",
    "2. Variable predict behavior or if 1000 variables then not possibel to consume all\n",
    "\n",
    "##### Five methods of building models\n",
    "###### Step wise regression (1-4)\n",
    "1. All in: Use all your variables or you know these are true predictor, or they are fixed or you dont have choice. Prior knowledge or you have you use\n",
    "\n",
    "2. Backward Elimination: step:1 select significance level to stay in model (SL:0.05)step:2 Fit all full model with alll possible preditors\n",
    "step:3 consider the predictor with the highest P value if p > sl go to step 4 else FIN\n",
    "step:4 Remove the predictor\n",
    "step:5 Fit the model without this variable\n",
    "step:6 got to step 3\n",
    "FIN: Your model is ready\n",
    "3. Forward selection: \n",
    "4. Bidirectional Elimination\n",
    "---------------------------\n",
    "5. Score comparison\n",
    "6. All possible models: Select a criterion of goodness of fit, Construct all possible regression model 2**n - 1 total cominations, Select the one with the best criterion, models is ready\n",
    "Not a good approach\n",
    "\n",
    "### In this we are using Backword elemination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data preprocessing:\n",
    "1. Import\n",
    "2. Read dataset\n",
    "3. Split Data\n",
    "4. State coulmn is in non numerical or have category so we need to convert into dummy variable\n",
    "Apply one hot encoding\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192261.83, 191792.06, 191050.39, 182901.99, 166187.94, 156991.12,\n",
       "       156122.51, 155752.6 , 152211.77, 149759.96, 146121.95, 144259.4 ,\n",
       "       141585.52, 134307.35, 132602.65, 129917.04, 126992.93, 125370.37,\n",
       "       124266.9 , 122776.86, 118474.03, 111313.02, 110352.25, 108733.99,\n",
       "       108552.04, 107404.34, 105733.54, 105008.31, 103282.38, 101004.64,\n",
       "        99937.59,  97483.56,  97427.84,  96778.92,  96712.8 ,  96479.51,\n",
       "        90708.19,  89949.14,  81229.06,  81005.76,  78239.91,  77798.83,\n",
       "        71498.49,  69758.98,  65200.33,  64926.08,  49490.75,  42559.73,\n",
       "        35673.41,  14681.4 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "dataset = pd.read_csv('startups.csv')\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical data using one hot encoding\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder=\"passthrough\")\n",
    "x = np.array(ct.fit_transform(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create 4 seperate set\n",
    "# 1. X train: matrix of feature of training set\n",
    "# 2. X test: matrix of feature of test set\n",
    "# 3. Y train: matrix of independent variable of train set \n",
    "# 4. Y Test: matrix of independent variable of test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In multiple linear regredssion no need to apply feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06],\n",
       "       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97427.84,  81005.76, 111313.02,  90708.19, 122776.86,  71498.49,\n",
       "        14681.4 , 105733.54, 110352.25, 134307.35,  77798.83, 125370.37,\n",
       "        64926.08, 108552.04, 108733.99, 166187.94,  96778.92, 132602.65,\n",
       "        99937.59, 146121.95, 103282.38,  65200.33,  96712.8 , 124266.9 ,\n",
       "       118474.03, 107404.34, 156122.51, 155752.6 ,  42559.73, 191792.06,\n",
       "       126992.93, 192261.83, 129917.04, 156991.12, 144259.4 , 149759.96,\n",
       "       152211.77, 141585.52,  69758.98,  89949.14])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([105008.31,  96479.51,  78239.91,  81229.06, 191050.39, 182901.99,\n",
       "        35673.41, 101004.64,  49490.75,  97483.56])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one that one highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the multiple linear regression model on training set\n",
    "# Do we have something to remove dummy variables: No\n",
    "# These are automatically deduct\n",
    "# Do we have to feature to select: No\n",
    "# Automatically built, included in scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114664.42 105008.31]\n",
      " [ 90593.16  96479.51]\n",
      " [ 75692.84  78239.91]\n",
      " [ 70221.89  81229.06]\n",
      " [179790.26 191050.39]\n",
      " [171576.92 182901.99]\n",
      " [ 49753.59  35673.41]\n",
      " [102276.66 101004.64]\n",
      " [ 58649.38  49490.75]\n",
      " [ 98272.03  97483.56]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the test result\n",
    "# to predict y test we need to put x_test in predict\n",
    "# this time we have 4 feature\n",
    "# we will display 2 vectors, y test and y pred\n",
    "y_pred = regressor.predict(x_test)\n",
    "# instead of feature scaling use\n",
    "np.set_printoptions(precision=2)\n",
    "# return 2 vectors, actual and test together using concatenate\n",
    "# reshape vector horizontal  to vertical\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([105008.31,  96479.51,  78239.91,  81229.06, 191050.39, 182901.99,\n",
       "        35673.41, 101004.64,  49490.75,  97483.56])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred: prediction values\n",
    "# y_test: actual values\n",
    "# we need to visualize the y_pred and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
